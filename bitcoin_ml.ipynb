{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef62711-3138-4bc9-bda6-596f23ce0f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "import keras.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161247b1-1674-4c8f-be67-831638e26b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the BITCOIN csv into the notebook\n",
    "btc_df = pd.read_csv(\n",
    "    Path(\"./Resources/bitcoin.csv\"),\n",
    "    index_col = 'Date',\n",
    "    infer_datetime_format=True, \n",
    "    parse_dates=True\n",
    ")\n",
    "\n",
    "# Review the DataFrame\n",
    "btc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b9c34-0eb5-414d-9ff1-ab09cc5f3f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c46105-8979-4316-9368-d49032925022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of categorical variables \n",
    "#categorical_variables = list(stoch_df.dtypes[stoch_df.dtypes == \"object\"].index)\n",
    "categorical_variables = list(btc_df[['custom_signal']])\n",
    "# Display the categorical variables list\n",
    "display(categorical_variables[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1284165-1659-44cd-ba1d-9ac567997bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "    # sparse = False, results in an array\n",
    "    # sparse = True (default), results in a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc104c22-b85f-464f-a0ce-57bae597a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorcal variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(btc_df[categorical_variables])\n",
    "encoded_data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf0aef-7529-4391-a1ea-872f2ced811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the encoded variables\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_data,\n",
    "    columns = enc.get_feature_names(categorical_variables)\n",
    "        # function gathers column names and assigns them to the new DataFrame\n",
    ")\n",
    "\n",
    "# set index of encoded_df\n",
    "encoded_df.set_index(btc_df.index, inplace=True)\n",
    "\n",
    "# Review the DataFrame\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb36f82f-decb-4730-8759-6345c5371942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_df.drop(columns=['Stoch_Entry/Exit_nan','MACD_Entry/Exit_nan'],inplace=True)\n",
    "\n",
    "# Review the DataFrame\n",
    "#encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53308105-85d1-43e3-b27b-3d5c5cf44608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame\n",
    "side_numeric = btc_df.drop(columns=['custom_signal'])\n",
    "\n",
    "# Review the DataFrame\n",
    "side_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc152180-07a6-47ab-a5e0-42910a78b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_ohe_df = pd.concat([encoded_df,side_numeric],axis=1)\n",
    "\n",
    "# Review the number of columns\n",
    "len(btc_ohe_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5416b0-6d8d-4ad6-9827-e574ebfafeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = btc_ohe_df.drop(columns=['custom_signal_-2','custom_signal_0','custom_signal_2'])\n",
    "\n",
    "# Review the number of columns\n",
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54b282-79c0-43af-af46-24386502bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target set selecting the Signal column and assiging it to y\n",
    "y = btc_ohe_df[['custom_signal_-2','custom_signal_0','custom_signal_2']]\n",
    "\n",
    "# Review the number of columns\n",
    "len(y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c8cb1-6c9d-41d0-ad4b-375a02c97cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "    # test_size=x\n",
    "# Review the DataFrame\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e982589-4c68-44af-b781-116ed0c0b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min() + DateOffset(hours=1)\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0206eb-7b8e-42fb-881d-0589a3f71330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ending period for the training data with an offset of 3 months\n",
    "training_end = X.index.min() + DateOffset(months=3)\n",
    "    # Keep training less than 50% of total DataFrame\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fcdba5-d696-4a59-a474-63532a2598c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952705c-f40f-4d42-b08c-91f596eaa55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Review the X_test DataFrame\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53664d16-c5eb-4630-aa31-0cd4cc91cbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features DataFrames\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "## Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb2b84-99b8-4759-b18e-15d0df12db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACD Neural Network\n",
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ac4d9-cfa9-40f4-a3aa-db35b16b6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons = 3\n",
    "    # equal to one because we only have one target, y.\n",
    "    # should be equal to the number of target columns we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba4de6e-4a4c-4f0f-9020-5655754e18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = '\\n'\n",
    "\n",
    "# Define the number of hidden nodes for the first hidden layer and second layer\n",
    "hidden_nodes_layer1 =  (number_input_features + number_output_neurons) //2\n",
    "hidden_nodes_layer2 = (hidden_nodes_layer1 + number_output_neurons) //2\n",
    "hidden_nodes_layer3 = (hidden_nodes_layer2 + number_output_neurons) //2 \n",
    "hidden_nodes_layer4 = (hidden_nodes_layer3 + number_output_neurons) //2 \n",
    "hidden_nodes_layer5 = (hidden_nodes_layer4 + number_output_neurons) //2 \n",
    "\n",
    "# Review the number hidden nodes in the first and second layer\n",
    "print(f'# of neurons in the first hidden layer: {hidden_nodes_layer1}{n}# of neurons in the second hidden layer: {hidden_nodes_layer2}{n}# of neurons in the third hidden layer: {hidden_nodes_layer3}'\n",
    "    f'{n}# of neurons in the fourth hidden layer: {hidden_nodes_layer4}{n}# of neurons in the fifth hidden layer: {hidden_nodes_layer5}{n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adfa9c6-9de8-4e17-8b4f-b187090e61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c30661-de67-4740-9937-bba3302a1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1,input_dim=number_input_features,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb171364-931e-4374-bde8-4a97e04a2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38160f8-dd87-4817-8f89-7876fee250a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the third hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer3,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dddb05-2632-46f8-b6bf-22c7ea6d1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the fourth hidden layer\n",
    "#nn.add(Dense(units=hidden_nodes_layer4,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab6b5b-d342-423a-b315-e6f91b77f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the fifth hidden layer\n",
    "#nn.add(Dense(units=hidden_nodes_layer5,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39866705-3743-436b-a95a-ff754077d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(units=number_output_neurons,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ac3e9-e815-453f-9fcf-45a19f1754fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4278c72-1bd0-42ae-b125-48e15c593410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    # metric exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a113bb1f-3be0-4966-be9e-bdaba26d9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn.fit(X_train_scaled,y_train,epochs=100, verbose=3)\n",
    "    # make sure to use X_train_scaled rather than X_train\n",
    "    # verbose=3, reduces the graphics displayed per epoch. in turn this increases the overall speed of the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78295c9-d506-4962-9565-1514edb11c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "nn_btc_keras= nn.evaluate(X_test_scaled,y_test, verbose=3)\n",
    "\n",
    "# Display the model loss and accuracy results\n",
    "abc = print(f\"KERAS: {nn_btc_keras}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd29e00-f05e-46be-904d-428fab8d8ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss: 0.2134855091571808, Accuracy: 0.9853846430778503\n",
    "# # of neurons in the first hidden layer: 14\n",
    "# of neurons in the second hidden layer: 8\n",
    "# of neurons in the third hidden layer: 5\n",
    "# of neurons in the fourth hidden layer: 4\n",
    "# of neurons in the fifth hidden layer: 3\n",
    "# relu activations functions with softmax for the output layer\n",
    "# loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy, mse']\n",
    "# 3 output neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a788c6-a6ed-4d94-a556-87713feba842",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc048a-df03-4dca-a8d7-fdbdf9c7f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b8503-7d9b-4058-9674-455edf74316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = list(btc_df[['MACD_Signal','RSI_Signal','Stoch_Signal','MACD_Entry/Exit','Stoch_Entry/Exit']])\n",
    "categorical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7680d-b3ad-4dd7-aef7-af5b5755e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorcal variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(btc_df[categorical_variables])\n",
    "encoded_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e70fb64-e776-48d6-8795-75e24a56ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the encoded variables\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_data,\n",
    "    columns = enc.get_feature_names(categorical_variables)\n",
    "        # function gathers column names and assigns them to the new DataFrame\n",
    ")\n",
    "\n",
    "# set index of encoded_df\n",
    "encoded_df.set_index(btc_df.index, inplace=True)\n",
    "\n",
    "# Review the DataFrame\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1fa5ae-7515-4d93-89ca-02cca9dbf6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame\n",
    "#side_numeric = btc_df.drop(columns=['MACD_Signal_-1.0','MACD_Signal_1.0','RSI_Signal_-1.0','RSI_Signal_0.0','RSI_Signal_1.0','Stoch_Signal_-1.0','Stoch_Signal_1.0','','','','',''])\n",
    "#side_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d47f5-1da6-4ef0-9b2c-29dab7464d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#btc_df = pd.concat([encoded_df,side_numeric],axis=1)\n",
    "#btc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ba1c7-efca-445b-8e6c-44d65ebd5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f3120-999c-424b-9edd-7598b96c82bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = btc_df.drop(columns=['custom_signal'])\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b917ef-6553-4235-9391-b5f0f160b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target set selecting the Signal column and assiging it to y\n",
    "y = btc_df['custom_signal']\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af67480-61b1-43c9-9f75-706aaaed0173",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "    # test_size=x\n",
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19809aa6-ba4d-4f92-9d67-994a784abbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b2917-9b27-41a7-a3b0-4ae58dfae68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min() + DateOffset(hours=1)\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90e5fa-b1b5-4750-9213-99a20db44f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ending period for the training data with an offset of 3 months\n",
    "training_end = X.index.min() + DateOffset(months=3)\n",
    "    # Keep training less than 50% of total DataFrame\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f9d63-190f-4f99-b96d-691f60c0d689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Review the X_train DataFrame\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce238c-b610-4561-8e92-199ae3dd7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end+DateOffset(hours=1):]\n",
    "y_test = y.loc[training_end+DateOffset(hours=1):]\n",
    "\n",
    "# Review the X_test DataFrame\n",
    "display(X_test.head())\n",
    "display(X_test.tail())\n",
    "#     # NOT SURE IF DATEOFFSET IS NECESSARY FOR X/Y TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb02587-711a-405f-b778-93ea4d754444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features DataFrames\n",
    "# Create a StandardScaler instance\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d1dc2-b8d5-427a-8021-94baf0821f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From SVM, instantiate SVC classifier model instance\n",
    "btc_tree = RandomForestClassifier(random_state=1)\n",
    " \n",
    "# Fit the model to the data using the training data\n",
    "btc_tree.fit(X_train_scaled,y_train)\n",
    " \n",
    "# Use the testing data to make the model predictions\n",
    "y_btc_tree_pred = btc_tree.predict(X_test_scaled)\n",
    "\n",
    "btc_tree_class = classification_report(y_test,y_btc_tree_pred)\n",
    "btc_tree_matrix = confusion_matrix(y_test,y_btc_tree_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5118ce-a3e8-4bef-b0bb-958b09821103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the random oversampler model\n",
    "\n",
    "random_sampler = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fit the original training data to the random_oversampler model\n",
    "X_resampled, y_resampled = random_sampler.fit_resample(X_train,y_train)\n",
    "\n",
    "\n",
    "y_resampled.value_counts()\n",
    "\n",
    "# Do we have to create this before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4036576-8ede-4315-aaec-6abd39047d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stoch RandomForestClassifier Oversampled\n",
    "btc_tree_os = RandomForestClassifier(random_state=1)\n",
    " \n",
    "# Fit the model to the data using the training data\n",
    "btc_tree_os.fit(X_resampled,y_resampled)\n",
    " \n",
    "# Use the testing data to make the model predictions\n",
    "y_btc_tree_pred_os = btc_tree_os.predict(X_test)\n",
    "\n",
    "btc_tree_class_os = classification_report(y_test,y_btc_tree_pred_os)\n",
    "btc_tree_matrix_os = confusion_matrix(y_test,y_btc_tree_pred_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f80d12-4404-437d-ae59-f73b2fdf564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # From LogisticRegression, instantiate LogisticRegression classifier model instance\n",
    "btc_log = LogisticRegression(random_state=1)\n",
    " \n",
    "# Fit the model to the data using the training data\n",
    "btc_log.fit(X_train_scaled,y_train)\n",
    " \n",
    "# # Use the testing data to make the model predictions\n",
    "y_btc_log_pred = btc_log.predict(X_test_scaled)\n",
    "\n",
    "# # Create and save confusion matrix and classification report to a variable name\n",
    "btc_log_matrix = confusion_matrix(y_test,y_btc_log_pred)\n",
    "btc_log_class = classification_report(y_test,y_btc_log_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e3080-bcea-4665-a0d7-39608d0b8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(btc_log_matrix)\n",
    "print(btc_log_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d48ab-9b96-4d5e-a537-29bec675ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From LogisticRegression, instantiate LogisticRegression classifier model instance\n",
    "btc_log_os = LogisticRegression(random_state=1)\n",
    " \n",
    "# Fit the model to the data using the training data\n",
    "btc_log_os.fit(X_resampled,y_resampled)\n",
    " \n",
    "# # Use the testing data to make the model predictions\n",
    "y_btc_log_pred_os = btc_log_os.predict(X_test)\n",
    "\n",
    "# Create and save confusion matrix and classification report to a variable name\n",
    "btc_log_matrix_os = confusion_matrix(y_test,y_btc_log_pred_os)\n",
    "btc_log_class_os = classification_report(y_test,y_btc_log_pred_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a8c3c4-3ab7-4fae-a48a-270c4fa4649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to create a model which uses a lot more OHE catagorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98463fdf-3a3a-4b4e-b859-38d4126c1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NN')\n",
    "print(f'KERAS:{nn_btc_keras}')\n",
    "print('Random Forest')\n",
    "print(btc_tree_class)\n",
    "print(btc_tree_matrix)\n",
    "print('OS -- Random Forest')\n",
    "print(btc_tree_class_os)\n",
    "print(btc_tree_matrix_os)\n",
    "print('log Reg')\n",
    "print(btc_log_class_os)\n",
    "print(btc_log_matrix_os)\n",
    "print('OS -- Log Reg')\n",
    "print(btc_log_class_os)\n",
    "print(btc_log_matrix_os)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
